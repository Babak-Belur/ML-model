{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradeForecasting_V2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut9oi-7LWgSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92fc0704-eca1-4bf2-a68c-96a8ec41808e"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "47JMZKRUH2cy",
        "outputId": "3321e3f3-66c1-48d6-9330-3642aebd1927"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4062a1cf-f049-4178-9673-83787f4b7235\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4062a1cf-f049-4178-9673-83787f4b7235\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"nanamulyanamaghfur\",\"key\":\"11da37dbb74c981039e2be0329480536\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeVIw08iH6Kw"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ist-bEbKH8LV",
        "outputId": "d321989a-8974-49e9-b3f4-251d650cc362"
      },
      "source": [
        "!kaggle datasets download -d larsen0966/student-performance-data-set"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading student-performance-data-set.zip to /content\n",
            "\r  0% 0.00/12.1k [00:00<?, ?B/s]\n",
            "\r100% 12.1k/12.1k [00:00<00:00, 18.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFAFFXRGH-Sh",
        "outputId": "9daabd76-e686-445a-94da-f42b4a8d415f"
      },
      "source": [
        "!unzip student-performance-data-set.zip -d student_performance"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  student-performance-data-set.zip\n",
            "  inflating: student_performance/student-por.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "JjDXIVuXIV3Y",
        "outputId": "d6138249-f8fc-4945-dc36-6de4cda48ae5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/student_performance/student-por.csv\")\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>reason</th>\n",
              "      <th>guardian</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>schoolsup</th>\n",
              "      <th>famsup</th>\n",
              "      <th>paid</th>\n",
              "      <th>activities</th>\n",
              "      <th>nursery</th>\n",
              "      <th>higher</th>\n",
              "      <th>internet</th>\n",
              "      <th>romantic</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>18</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>at_home</td>\n",
              "      <td>teacher</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>health</td>\n",
              "      <td>services</td>\n",
              "      <td>home</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>home</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  school sex  age address famsize Pstatus  ...  Walc  health absences  G1  G2  G3\n",
              "0     GP   F   18       U     GT3       A  ...     1       3        4   0  11  11\n",
              "1     GP   F   17       U     GT3       T  ...     1       3        2   9  11  11\n",
              "2     GP   F   15       U     LE3       T  ...     3       3        6  12  13  12\n",
              "3     GP   F   15       U     GT3       T  ...     1       5        0  14  14  14\n",
              "4     GP   F   16       U     GT3       T  ...     2       5        0  11  13  13\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHsanzfjSPxd"
      },
      "source": [
        "x = data[[\"studytime\", \"freetime\", \"G1\", \"G2\"]]\n",
        "y = data[\"G3\"] "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "BUUhuyhgSZNM",
        "outputId": "5fd16abb-c6c3-4fee-d4f6-0b199ad809a6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\"\"\"def NormalizeData(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "scaled_columns = [\"studytime\", \"freetime\"]\n",
        "\n",
        "for col in scaled_columns:\n",
        "  x[col] = NormalizeData(x[col])\"\"\"\n",
        "\n",
        "# Custom Normalization based on data characteristic\n",
        "\n",
        "x['studytime'] = x['studytime'] / 4\n",
        "x['freetime'] = x['freetime'] / 5\n",
        "\n",
        "# We rescale the grade system from base 20 into base 100\n",
        "x['G1'] = x['G1'] * 5 / 100\n",
        "x['G2'] = x['G2'] * 5 / 100 \n",
        "\n",
        "x.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>studytime</th>\n",
              "      <th>freetime</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   studytime  freetime    G1    G2\n",
              "0       0.50       0.6  0.00  0.55\n",
              "1       0.50       0.6  0.45  0.55\n",
              "2       0.50       0.6  0.60  0.65\n",
              "3       0.75       0.4  0.70  0.70\n",
              "4       0.50       0.6  0.55  0.65"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6sIL3OpSbfe",
        "outputId": "fae67d93-f128-45f8-a78a-1efbe96e1bda"
      },
      "source": [
        "y = y * 5 / 100\n",
        "\n",
        "y.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.55\n",
              "1    0.55\n",
              "2    0.60\n",
              "3    0.70\n",
              "4    0.65\n",
              "Name: G3, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Nw56BJSd6E"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laiVyGx_Tqy5",
        "outputId": "ef926b6b-3286-499a-c26e-102b80315c09"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(486, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ISydBYTyOu",
        "outputId": "8c8f4594-87b5-446e-9a65-20139b5e0a87"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(486,)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF36lkXfSir0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(4, input_shape=[4], activation=\"relu\")) \n",
        "model.add(Dense(4, activation=\"relu\")) \n",
        "model.add(Dense(2, activation=\"relu\")) \n",
        "model.add(Dense(1))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjgzTqu7T_0N"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=tf.keras.losses.LogCosh())"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOwXPiBuUeHs",
        "outputId": "c49ee023-4197-47b6-c142-ac003a019099"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_32 (Dense)             (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 53\n",
            "Trainable params: 53\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7mM5PHfUBWY",
        "outputId": "41729806-0d35-412f-c48b-e1c58d0ec424"
      },
      "source": [
        "history = model.fit(x= x_train, y= y_train, batch_size=32, epochs=500, validation_data=(x_test, y_test))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 0.1754 - val_loss: 0.1600\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1627 - val_loss: 0.1439\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.1406 - val_loss: 0.1194\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1145 - val_loss: 0.0941\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.0697\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0634 - val_loss: 0.0467\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0281\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0157\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0100\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0087\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0086\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0085\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0082\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0079\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0077\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0073\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0068\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0064\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0059\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0055\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0053\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0050\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0049\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0047\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0045\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0042\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0041\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0038\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0035\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0034\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0033\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0033\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0033\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0033\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0033\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0032\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0032\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0032\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0032\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0031\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0031\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0031\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0031\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0031\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0031\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0030\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0030\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0030\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0027\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0029\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0028\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0027\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "TRYY94b0V4sQ",
        "outputId": "a108d250-34fa-47c9-b52c-a22e92adf00f"
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(15,8))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbef1e43c10>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lubRXMOWSMk"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7PJwiICXdk-",
        "outputId": "fcbfb2b4-3670-40ec-dba9-4beb548fecfa"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
        "\n",
        "print(\"The absolute mean error :\",mean_absolute_error(y_test, predictions))\n",
        "print(\"The squared mean error :\",mean_squared_error(y_test, predictions))\n",
        "print(\"The Variance Score :\", explained_variance_score(y_test, predictions))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The absolute mean error : 0.043307731268596064\n",
            "The squared mean error : 0.005415456726847286\n",
            "The Variance Score : 0.7832525932654515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "W02gQaGGWRk8",
        "outputId": "111d1a8f-f52c-47cc-b28f-9614dbfea559"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(18,8))\n",
        "plt.scatter(y_test, predictions)\n",
        "plt.scatter(y_test,y_test,color=\"red\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fbef2060fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CruLXog2YR4t",
        "outputId": "29d6ecb4-cbce-497a-f103-cc0acc5d6e58"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "sq = r2_score(y_test, predictions)\n",
        "print('coefficient of determination:', sq)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coefficient of determination: 0.777714363306083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTfWy47WaXtE"
      },
      "source": [
        "model.save(\"GF_V2_model.h5\")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cN1iOrbkeDEu",
        "outputId": "40acd2e8-0667-4f06-9c71-d45cb672ed76"
      },
      "source": [
        "x_test.head()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>studytime</th>\n",
              "      <th>freetime</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>0.75</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     studytime  freetime    G1    G2\n",
              "175       0.50       0.8  0.35  0.30\n",
              "452       0.50       0.8  0.45  0.50\n",
              "463       0.75       0.8  0.70  0.55\n",
              "418       0.25       0.2  0.65  0.70\n",
              "566       0.25       0.6  0.45  0.35"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zOhNf3ueKVu",
        "outputId": "36c1c48e-ec95-4564-bfe0-269983986614"
      },
      "source": [
        "y_test.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175    0.40\n",
              "452    0.55\n",
              "463    0.60\n",
              "418    0.70\n",
              "566    0.45\n",
              "Name: G3, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di2uT88ueMtK",
        "outputId": "25e0a8d9-3c92-4423-b695-b45d197cfd8e"
      },
      "source": [
        "predictions = model.predict(x_test.head())\n",
        "print(np.round(predictions, 2))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.31]\n",
            " [0.51]\n",
            " [0.6 ]\n",
            " [0.7 ]\n",
            " [0.37]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}