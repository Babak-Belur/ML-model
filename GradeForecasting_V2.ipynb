{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradeForecasting_V2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut9oi-7LWgSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3850331a-7f8f-466a-890d-3e6fecc0b4fc"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "47JMZKRUH2cy",
        "outputId": "6c5a24c9-b49f-48d6-c427-bb4047057b21"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8bd9a424-0f8f-4088-b14e-55c8b7ffd99b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8bd9a424-0f8f-4088-b14e-55c8b7ffd99b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"nanamulyanamaghfur\",\"key\":\"11da37dbb74c981039e2be0329480536\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeVIw08iH6Kw"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ist-bEbKH8LV",
        "outputId": "93512f98-05b3-4064-8ae0-aca3648e0dd7"
      },
      "source": [
        "!kaggle datasets download -d larsen0966/student-performance-data-set"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading student-performance-data-set.zip to /content\n",
            "\r  0% 0.00/12.1k [00:00<?, ?B/s]\n",
            "\r100% 12.1k/12.1k [00:00<00:00, 9.97MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFAFFXRGH-Sh",
        "outputId": "769a028e-45f9-4e24-9403-bf28bd279710"
      },
      "source": [
        "!unzip student-performance-data-set.zip -d student_performance"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  student-performance-data-set.zip\n",
            "  inflating: student_performance/student-por.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "JjDXIVuXIV3Y",
        "outputId": "c0e0100a-c186-40a1-ea4b-8ae4a1748403"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/student_performance/student-por.csv\")\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>reason</th>\n",
              "      <th>guardian</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>schoolsup</th>\n",
              "      <th>famsup</th>\n",
              "      <th>paid</th>\n",
              "      <th>activities</th>\n",
              "      <th>nursery</th>\n",
              "      <th>higher</th>\n",
              "      <th>internet</th>\n",
              "      <th>romantic</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>18</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>at_home</td>\n",
              "      <td>teacher</td>\n",
              "      <td>course</td>\n",
              "      <td>mother</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>course</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>health</td>\n",
              "      <td>services</td>\n",
              "      <td>home</td>\n",
              "      <td>mother</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>home</td>\n",
              "      <td>father</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  school sex  age address famsize Pstatus  ...  Walc  health absences  G1  G2  G3\n",
              "0     GP   F   18       U     GT3       A  ...     1       3        4   0  11  11\n",
              "1     GP   F   17       U     GT3       T  ...     1       3        2   9  11  11\n",
              "2     GP   F   15       U     LE3       T  ...     3       3        6  12  13  12\n",
              "3     GP   F   15       U     GT3       T  ...     1       5        0  14  14  14\n",
              "4     GP   F   16       U     GT3       T  ...     2       5        0  11  13  13\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHsanzfjSPxd"
      },
      "source": [
        "x = data[[\"studytime\",\"paid\",\"activities\", \"higher\", \"internet\", \"freetime\", \"health\", \"G1\", \"G2\"]]\n",
        "y = data[\"G3\"]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6B7XopxSSVRR",
        "outputId": "2449a584-7e92-405e-a59c-2c1b6cccb8cc"
      },
      "source": [
        "categorical_columns = ['paid','activities','higher','internet']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    col_ohe = pd.get_dummies(x[col], prefix=col)\n",
        "    x = pd.concat((x, col_ohe), axis=1).drop(col, axis=1)\n",
        "\n",
        "x.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>studytime</th>\n",
              "      <th>freetime</th>\n",
              "      <th>health</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>paid_no</th>\n",
              "      <th>paid_yes</th>\n",
              "      <th>activities_no</th>\n",
              "      <th>activities_yes</th>\n",
              "      <th>higher_no</th>\n",
              "      <th>higher_yes</th>\n",
              "      <th>internet_no</th>\n",
              "      <th>internet_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   studytime  freetime  health  ...  higher_yes  internet_no  internet_yes\n",
              "0          2         3       3  ...           1            1             0\n",
              "1          2         3       3  ...           1            0             1\n",
              "2          2         3       3  ...           1            0             1\n",
              "3          3         2       5  ...           1            0             1\n",
              "4          2         3       5  ...           1            1             0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BUUhuyhgSZNM",
        "outputId": "743256c8-cf96-4f92-b505-3202a6678995"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def NormalizeData(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "scaled_columns = [\"studytime\", \"freetime\", \"health\"]\n",
        "\n",
        "for col in scaled_columns:\n",
        "  x[col] = NormalizeData(x[col])\n",
        "\n",
        "x['G1'] = x['G1'] * 5 / 100\n",
        "x['G2'] = x['G2'] * 5 / 100 \n",
        "\n",
        "x.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>studytime</th>\n",
              "      <th>freetime</th>\n",
              "      <th>health</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>paid_no</th>\n",
              "      <th>paid_yes</th>\n",
              "      <th>activities_no</th>\n",
              "      <th>activities_yes</th>\n",
              "      <th>higher_no</th>\n",
              "      <th>higher_yes</th>\n",
              "      <th>internet_no</th>\n",
              "      <th>internet_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   studytime  freetime  health  ...  higher_yes  internet_no  internet_yes\n",
              "0   0.333333      0.50     0.5  ...           1            1             0\n",
              "1   0.333333      0.50     0.5  ...           1            0             1\n",
              "2   0.333333      0.50     0.5  ...           1            0             1\n",
              "3   0.666667      0.25     1.0  ...           1            0             1\n",
              "4   0.333333      0.50     1.0  ...           1            1             0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6sIL3OpSbfe",
        "outputId": "d5d2401c-78be-4670-b739-7582df41e0a3"
      },
      "source": [
        "y = y * 5 / 100\n",
        "\n",
        "y.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.55\n",
              "1    0.55\n",
              "2    0.60\n",
              "3    0.70\n",
              "4    0.65\n",
              "Name: G3, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Nw56BJSd6E"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laiVyGx_Tqy5",
        "outputId": "923e0d6e-8284-4698-c2bf-4d3394ff202f"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(486, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ISydBYTyOu",
        "outputId": "200a33f7-780c-4b51-cd39-6a973fe69eaf"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(486,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF36lkXfSir0"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(13, input_shape=[13], activation=\"relu\")) \n",
        "model.add(Dense(13, activation=\"relu\")) \n",
        "model.add(Dense(13, activation=\"relu\")) \n",
        "model.add(Dense(13, activation=\"relu\"))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjgzTqu7T_0N"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"mse\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOwXPiBuUeHs",
        "outputId": "65e794f0-0ca5-448a-a419-b00ef09c0ead"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 742\n",
            "Trainable params: 742\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7mM5PHfUBWY",
        "outputId": "5f17b985-25e0-4f44-afdb-ba45ff0e728c"
      },
      "source": [
        "history = model.fit(x= x_train, y= y_train, batch_size=32, epochs=500, validation_data=(x_test, y_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 0.1543 - val_loss: 0.0467\n",
            "Epoch 2/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.0291\n",
            "Epoch 3/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0222\n",
            "Epoch 4/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0191\n",
            "Epoch 5/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0180\n",
            "Epoch 6/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0170\n",
            "Epoch 7/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0161\n",
            "Epoch 8/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0155\n",
            "Epoch 9/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0146\n",
            "Epoch 10/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0139\n",
            "Epoch 11/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0131\n",
            "Epoch 12/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0124\n",
            "Epoch 13/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0116\n",
            "Epoch 14/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0114\n",
            "Epoch 15/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0104\n",
            "Epoch 16/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0101\n",
            "Epoch 17/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.0092\n",
            "Epoch 18/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0084\n",
            "Epoch 19/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0078\n",
            "Epoch 20/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 21/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0067\n",
            "Epoch 22/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 23/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0057\n",
            "Epoch 24/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0053\n",
            "Epoch 25/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0053\n",
            "Epoch 26/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0057\n",
            "Epoch 27/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0050\n",
            "Epoch 28/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0056\n",
            "Epoch 29/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0049\n",
            "Epoch 30/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0047\n",
            "Epoch 31/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0047\n",
            "Epoch 32/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0046\n",
            "Epoch 33/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0048\n",
            "Epoch 34/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0045\n",
            "Epoch 35/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0044\n",
            "Epoch 36/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0044\n",
            "Epoch 37/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0043\n",
            "Epoch 38/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0043\n",
            "Epoch 39/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0043\n",
            "Epoch 40/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0043\n",
            "Epoch 41/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0043\n",
            "Epoch 42/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0043\n",
            "Epoch 43/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0042\n",
            "Epoch 44/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0043\n",
            "Epoch 45/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0044\n",
            "Epoch 46/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0042\n",
            "Epoch 47/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0042\n",
            "Epoch 48/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0042\n",
            "Epoch 49/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0042\n",
            "Epoch 50/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0041\n",
            "Epoch 51/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0041\n",
            "Epoch 52/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0042\n",
            "Epoch 53/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0041\n",
            "Epoch 54/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0041\n",
            "Epoch 55/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 56/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 57/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0040\n",
            "Epoch 58/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 59/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0049\n",
            "Epoch 60/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0040\n",
            "Epoch 61/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 62/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 63/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 64/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 65/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 66/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 67/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 68/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 69/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 70/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0039\n",
            "Epoch 71/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0043\n",
            "Epoch 72/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0040\n",
            "Epoch 73/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0042\n",
            "Epoch 74/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0042\n",
            "Epoch 75/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0041\n",
            "Epoch 76/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 77/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0040\n",
            "Epoch 78/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 79/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0039\n",
            "Epoch 80/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 81/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0040\n",
            "Epoch 82/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0040\n",
            "Epoch 83/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0042\n",
            "Epoch 84/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 85/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0042\n",
            "Epoch 86/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0040\n",
            "Epoch 87/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 88/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0041\n",
            "Epoch 89/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0041\n",
            "Epoch 90/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 91/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 92/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 93/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 94/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0041\n",
            "Epoch 95/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 96/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0040\n",
            "Epoch 97/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 98/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0041\n",
            "Epoch 99/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 100/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0040\n",
            "Epoch 101/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 102/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 103/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 104/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 105/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0042\n",
            "Epoch 106/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 107/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 108/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 109/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0042\n",
            "Epoch 110/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0044\n",
            "Epoch 111/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0044\n",
            "Epoch 112/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 113/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0043\n",
            "Epoch 114/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 115/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0050\n",
            "Epoch 116/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0050\n",
            "Epoch 117/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 118/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0051\n",
            "Epoch 119/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0046\n",
            "Epoch 120/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0046\n",
            "Epoch 121/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0046\n",
            "Epoch 122/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 123/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0046\n",
            "Epoch 124/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0046\n",
            "Epoch 125/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0048\n",
            "Epoch 126/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0053\n",
            "Epoch 127/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0048\n",
            "Epoch 128/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0045\n",
            "Epoch 129/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 130/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0046\n",
            "Epoch 131/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 132/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 133/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0045\n",
            "Epoch 134/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 135/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 136/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 137/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0049\n",
            "Epoch 138/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0047\n",
            "Epoch 139/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 140/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 141/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 142/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 143/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0051\n",
            "Epoch 144/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0049\n",
            "Epoch 145/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0050\n",
            "Epoch 146/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0051\n",
            "Epoch 147/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
            "Epoch 148/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0048\n",
            "Epoch 149/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
            "Epoch 150/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 151/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0054\n",
            "Epoch 152/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0047\n",
            "Epoch 153/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0047\n",
            "Epoch 154/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0049\n",
            "Epoch 155/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 156/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
            "Epoch 157/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0050\n",
            "Epoch 158/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0048\n",
            "Epoch 159/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0055\n",
            "Epoch 160/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0058\n",
            "Epoch 161/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0048\n",
            "Epoch 162/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0048\n",
            "Epoch 163/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0049\n",
            "Epoch 164/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0050\n",
            "Epoch 165/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0048\n",
            "Epoch 166/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0047\n",
            "Epoch 167/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 168/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
            "Epoch 169/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0051\n",
            "Epoch 170/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0049\n",
            "Epoch 171/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 172/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0049\n",
            "Epoch 173/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
            "Epoch 174/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0049\n",
            "Epoch 175/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 176/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0049\n",
            "Epoch 177/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 178/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 179/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0049\n",
            "Epoch 180/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0049\n",
            "Epoch 181/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0050\n",
            "Epoch 182/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0049\n",
            "Epoch 183/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 184/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0047\n",
            "Epoch 185/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 186/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0047\n",
            "Epoch 187/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0047\n",
            "Epoch 188/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0049\n",
            "Epoch 189/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 190/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 191/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0051\n",
            "Epoch 192/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0049\n",
            "Epoch 193/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 194/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 195/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0047\n",
            "Epoch 196/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0049\n",
            "Epoch 197/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 198/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0046\n",
            "Epoch 199/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 200/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0047\n",
            "Epoch 201/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0046\n",
            "Epoch 202/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0046\n",
            "Epoch 203/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 204/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0053\n",
            "Epoch 205/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0047\n",
            "Epoch 206/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Epoch 207/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0050\n",
            "Epoch 208/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0051\n",
            "Epoch 209/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0050\n",
            "Epoch 210/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0050\n",
            "Epoch 211/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 212/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0049\n",
            "Epoch 213/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0049\n",
            "Epoch 214/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0047\n",
            "Epoch 215/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0049\n",
            "Epoch 216/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0047\n",
            "Epoch 217/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0049\n",
            "Epoch 218/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0047\n",
            "Epoch 219/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0050\n",
            "Epoch 220/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0046\n",
            "Epoch 221/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 222/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0051\n",
            "Epoch 223/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0052\n",
            "Epoch 224/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0047\n",
            "Epoch 225/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0053\n",
            "Epoch 226/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
            "Epoch 227/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0048\n",
            "Epoch 228/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0054\n",
            "Epoch 229/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0046\n",
            "Epoch 230/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0048\n",
            "Epoch 231/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0047\n",
            "Epoch 232/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 233/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0050\n",
            "Epoch 234/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 235/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0048\n",
            "Epoch 236/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 237/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 238/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 239/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0050\n",
            "Epoch 240/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0051\n",
            "Epoch 241/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0047\n",
            "Epoch 242/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 243/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0046\n",
            "Epoch 244/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 245/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0048\n",
            "Epoch 246/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 247/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0055\n",
            "Epoch 248/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0056\n",
            "Epoch 249/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 250/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0047\n",
            "Epoch 251/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0049\n",
            "Epoch 252/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0049\n",
            "Epoch 253/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0043\n",
            "Epoch 254/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0048\n",
            "Epoch 255/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0049\n",
            "Epoch 256/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0046\n",
            "Epoch 257/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0045\n",
            "Epoch 258/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0044\n",
            "Epoch 259/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0045\n",
            "Epoch 260/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
            "Epoch 261/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0048\n",
            "Epoch 262/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0048\n",
            "Epoch 263/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0044\n",
            "Epoch 264/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
            "Epoch 265/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0044\n",
            "Epoch 266/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0052\n",
            "Epoch 267/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0045\n",
            "Epoch 268/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0044\n",
            "Epoch 269/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 270/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0046\n",
            "Epoch 271/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 272/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0046\n",
            "Epoch 273/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 274/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0045\n",
            "Epoch 275/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0047\n",
            "Epoch 276/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0044\n",
            "Epoch 277/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 278/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0047\n",
            "Epoch 279/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
            "Epoch 280/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
            "Epoch 281/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
            "Epoch 282/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0047\n",
            "Epoch 283/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0044\n",
            "Epoch 284/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0047\n",
            "Epoch 285/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0047\n",
            "Epoch 286/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0047\n",
            "Epoch 287/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0051\n",
            "Epoch 288/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0044\n",
            "Epoch 289/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0046\n",
            "Epoch 290/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0043\n",
            "Epoch 291/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
            "Epoch 292/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0050\n",
            "Epoch 293/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0046\n",
            "Epoch 294/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 295/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0047\n",
            "Epoch 296/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 297/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0050\n",
            "Epoch 298/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0046\n",
            "Epoch 299/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0047\n",
            "Epoch 300/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 301/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 302/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0046\n",
            "Epoch 303/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0046\n",
            "Epoch 304/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0045\n",
            "Epoch 305/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 306/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0045\n",
            "Epoch 307/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0050\n",
            "Epoch 308/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0045\n",
            "Epoch 309/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0050\n",
            "Epoch 310/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0046\n",
            "Epoch 311/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0045\n",
            "Epoch 312/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 313/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 314/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 315/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0046\n",
            "Epoch 316/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 317/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0049\n",
            "Epoch 318/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 319/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0050\n",
            "Epoch 320/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0052\n",
            "Epoch 321/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0058\n",
            "Epoch 322/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 323/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 324/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 325/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0049\n",
            "Epoch 326/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 327/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 328/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 329/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0049\n",
            "Epoch 330/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 331/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 332/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0049\n",
            "Epoch 333/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0049\n",
            "Epoch 334/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 335/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0047\n",
            "Epoch 336/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 337/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 338/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0049\n",
            "Epoch 339/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 340/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 341/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 342/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0051\n",
            "Epoch 343/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0048\n",
            "Epoch 344/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0051\n",
            "Epoch 345/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 346/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0050\n",
            "Epoch 347/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 348/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 349/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 350/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0051\n",
            "Epoch 351/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 352/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0053\n",
            "Epoch 353/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0051\n",
            "Epoch 354/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0050\n",
            "Epoch 355/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 356/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 357/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 358/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 359/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 360/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 361/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 362/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 363/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 364/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 365/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 366/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 367/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 368/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0050\n",
            "Epoch 369/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 370/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0050\n",
            "Epoch 371/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0050\n",
            "Epoch 372/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 373/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 374/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0046\n",
            "Epoch 375/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 376/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0050\n",
            "Epoch 377/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 378/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 379/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0051\n",
            "Epoch 380/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0046\n",
            "Epoch 381/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0052\n",
            "Epoch 382/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 383/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0050\n",
            "Epoch 384/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 385/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0049\n",
            "Epoch 386/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0046\n",
            "Epoch 387/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0049\n",
            "Epoch 388/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 389/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 390/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0045\n",
            "Epoch 391/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 392/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 393/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 394/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 395/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 396/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 397/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 398/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0047\n",
            "Epoch 399/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 400/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0045\n",
            "Epoch 401/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 402/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0046\n",
            "Epoch 403/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 404/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 405/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 406/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 407/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 408/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 409/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 410/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0047\n",
            "Epoch 411/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0051\n",
            "Epoch 412/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 413/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0046\n",
            "Epoch 414/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0049\n",
            "Epoch 415/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0045\n",
            "Epoch 416/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 417/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0049\n",
            "Epoch 418/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0046\n",
            "Epoch 419/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 420/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 421/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0044\n",
            "Epoch 422/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0050\n",
            "Epoch 423/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 424/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 425/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0051\n",
            "Epoch 426/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 427/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 428/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0059\n",
            "Epoch 429/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 430/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 431/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0049\n",
            "Epoch 432/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0052\n",
            "Epoch 433/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0049\n",
            "Epoch 434/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 435/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0049\n",
            "Epoch 436/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 437/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 438/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 439/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 440/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0048\n",
            "Epoch 441/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 442/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 443/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 444/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 445/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 446/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 447/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 448/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0051\n",
            "Epoch 449/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0049\n",
            "Epoch 450/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0051\n",
            "Epoch 451/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0049\n",
            "Epoch 452/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 453/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0047\n",
            "Epoch 454/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0051\n",
            "Epoch 455/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 456/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0050\n",
            "Epoch 457/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0051\n",
            "Epoch 458/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0061\n",
            "Epoch 459/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 460/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 461/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 462/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 463/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0050\n",
            "Epoch 464/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 465/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0050\n",
            "Epoch 466/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0045\n",
            "Epoch 467/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0049\n",
            "Epoch 468/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 469/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 470/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0049\n",
            "Epoch 471/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0046\n",
            "Epoch 472/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0050\n",
            "Epoch 473/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 474/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 475/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0046\n",
            "Epoch 476/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 477/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 478/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 479/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 480/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0051\n",
            "Epoch 481/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0048\n",
            "Epoch 482/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0055\n",
            "Epoch 483/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 484/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0048\n",
            "Epoch 485/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0047\n",
            "Epoch 486/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 487/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0049\n",
            "Epoch 488/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0050\n",
            "Epoch 489/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0046\n",
            "Epoch 490/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 491/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0047\n",
            "Epoch 492/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0050\n",
            "Epoch 493/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0050\n",
            "Epoch 494/500\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0052\n",
            "Epoch 495/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 496/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0048\n",
            "Epoch 497/500\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 498/500\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0046\n",
            "Epoch 499/500\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0048\n",
            "Epoch 500/500\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "TRYY94b0V4sQ",
        "outputId": "f4037be9-cb1f-4b3c-8236-0709a0011a35"
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(15,8))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe88d7af310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lubRXMOWSMk"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7PJwiICXdk-",
        "outputId": "e00c6267-0d4b-4406-da38-07e8da7be645"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
        "\n",
        "print(\"The absolute mean error :\",mean_absolute_error(y_test, predictions))\n",
        "print(\"The squared mean error :\",mean_squared_error(y_test, predictions))\n",
        "print(\"The squared mean error :\",np.sqrt(mean_squared_error(y_test, predictions)))\n",
        "print(\"The Variance Score :\", explained_variance_score(y_test, predictions))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The absolute mean error : 0.04860896354804009\n",
            "The squared mean error : 0.004991777366253828\n",
            "The squared mean error : 0.07065251139381974\n",
            "The Variance Score : 0.8056029347720265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "W02gQaGGWRk8",
        "outputId": "2c933c80-ae06-40d4-994e-d0274608d847"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(18,8))\n",
        "plt.scatter(y_test, predictions)\n",
        "plt.scatter(y_test,y_test,color=\"red\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fe888c3d5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CruLXog2YR4t",
        "outputId": "4511e06f-cc94-4f28-b315-6f01da4031be"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "sq = r2_score(y_test, predictions)\n",
        "print('coefficient of determination:', sq)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coefficient of determination: 0.7973682502536241\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}